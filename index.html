<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Smart Traffic Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        body { margin: 0; overflow: hidden; background: #000; font-family: Arial, sans-serif; }
        video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
        #overlay-text {
            position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
            font-size: 5rem; font-weight: bold; text-align: center; z-index: 10; pointer-events: none;
        }
        #status { position: absolute; top: 10px; left: 10px; color: white; background: rgba(0,0,0,0.5); z-index: 20; padding: 5px; }
    </style>
</head>
<body>
    <div id="status">Caricamento AI...</div>
    <div id="overlay-text"></div>
    <video id="webcam" autoplay playsinline muted></video>
    <canvas id="canvas"></canvas>

    <script>
        const video = document.getElementById('webcam');
        const canvas = document.getElementById('canvas');
        const textOverlay = document.getElementById('overlay-text');
        const status = document.getElementById('status');
        const ctx = canvas.getContext('2d');
        let model;

        // Configurazione audio
        const beep = new Audio('https://actions.google.com/sounds/v1/alarms/beep_short.ogg');

        async function setupWebcam() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: "environment" }, // Usa camera posteriore
                audio: false
            });
            video.srcObject = stream;
            return new Promise((resolve) => video.onloadedmetadata = () => resolve());
        }

        async function analyzeColor(bbox) {
            // Analisi semplificata dei pixel nell'area del semaforo
            const [x, y, width, height] = bbox;
            const imageData = ctx.getImageData(x, y, width, height);
            let r = 0, g = 0, b = 0;
            
            for (let i = 0; i < imageData.data.length; i += 4) {
                r += imageData.data[i];
                g += imageData.data[i+1];
                b += imageData.data[i+2];
            }
            
            const total = imageData.data.length / 4;
            r /= total; g /= total; b /= total;

            if (r > g && r > b) return 'RED';
            if (g > r && g > b) return 'GREEN';
            if (r > 150 && g > 150 && b < 100) return 'YELLOW';
            return 'NONE';
        }

        async function predict() {
            const predictions = await model.detect(video);
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            let currentLight = 'NONE';

            predictions.forEach(p => {
                if (p.class === 'traffic light') {
                    // Disegna rettangolo Magenta
                    ctx.strokeStyle = '#FF00FF';
                    ctx.lineWidth = 4;
                    ctx.strokeRect(...p.bbox);

                    // Analisi logica semplificata (Posizione verticale luce)
                    // In un semaforo standard: Rosso (sopra), Giallo (centro), Verde (sotto)
                    // Per semplicità usiamo il colore dominante nell'area
                    const color = analyzeColor(p.bbox);
                }
            });

            // Simulazione logica basata su predizioni (per prototipo)
            // Nota: COCO-SSD rileva l'oggetto, la logica colore è sperimentale
            updateUI(predictions);

            requestAnimationFrame(predict);
        }

        function updateUI(predictions) {
            const trafficLight = predictions.find(p => p.class === 'traffic light');
            if (!trafficLight) {
                textOverlay.innerText = "";
                return;
            }

            // Nota: Qui implementiamo la logica richiesta
            // Per scopi di test, il sistema alterna o analizza la zona
            // In un ambiente reale servirebbe un modello custom per "Red Light"
            
            // ESEMPIO DI LOGICA DI OUTPUT:
            // Se rilevato, mostriamo un feedback visivo (simulato per il colore dominante)
            // Inserire qui logica specifica di riconoscimento stato
        }

        async function init() {
            status.innerText = "Accesso fotocamera...";
            await setupWebcam();
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            status.innerText = "Caricamento Modello...";
            model = await cocoSsd.load();
            status.innerText = "Sistema Attivo";
            predict();
        }

        init();
    </script>
</body>
</html>